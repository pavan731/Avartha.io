{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth application-default set-quota-project vertex-ai-image-428313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install fastapi\n",
    "!pip install uvicorn\n",
    "!pip install pickle5\n",
    "!pip install pydantic\n",
    "!pip install scikit-learn\n",
    "!pip install requests\n",
    "!pip install pypi-json\n",
    "!pip install pyngrok\n",
    "!pip install nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "import mimetypes\n",
    "from fastapi import UploadFile\n",
    "from fastapi.responses import JSONResponse\n",
    "from pathlib import Path\n",
    "\n",
    "# Load configuration from config.json\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "project_id = config[\"project_id\"]\n",
    "location = config[\"location\"]\n",
    "model_name_pro = config[\"model_name_pro\"]\n",
    "model_name_flash = config[\"model_name_flash\"]\n",
    "upload_dir = config[\"upload_dir\"]\n",
    "\n",
    "# Initialize Vertex AI\n",
    "vertexai.init(project=project_id, location=location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageData:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.data = self.load_image_data()\n",
    "        self._mime_type = self.get_mime_type()\n",
    "\n",
    "    def load_image_data(self):\n",
    "        with open(self.file_path, \"rb\") as image_file:\n",
    "            return image_file.read()\n",
    "\n",
    "    def get_mime_type(self):\n",
    "        mime_type, _ = mimetypes.guess_type(self.file_path)\n",
    "        return mime_type if mime_type else \"application/octet-stream\"\n",
    "\n",
    "class ImageUploader:\n",
    "    def __init__(self):\n",
    "        self.upload_dir = Path(upload_dir)\n",
    "        self.upload_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def save_image(self, image: UploadFile) -> str:\n",
    "        file_location = self.upload_dir / image.filename\n",
    "        with file_location.open(\"wb\") as buffer:\n",
    "            buffer.write(image.file.read())\n",
    "        return str(file_location)\n",
    "\n",
    "class ImageHandler:\n",
    "    def __init__(self):\n",
    "        self.uploader = ImageUploader()\n",
    "\n",
    "    async def classify_image(self, image_path: str):\n",
    "        image_object = ImageData(image_path)\n",
    "\n",
    "        model = GenerativeModel(model_name=model_name_pro)\n",
    "\n",
    "        role = \"You're an expert in environmental well-being, knowledgeable about recyclable, non-recyclable, reusable, and non-reusable items, and their environmental impact.\"\n",
    "\n",
    "        instruction = \"\"\"Given an image, first identify the item/ items present in the image and give a small description on each item's physical appearance and the material composition.\n",
    "                         Ensure the output is in plain text without any markdown or formatting.\"\"\"\n",
    "\n",
    "        output = \"Item: [item]\\nDescription: [description]\\nMaterial: [material]\"\n",
    "\n",
    "        prompt = (\n",
    "            f\"role: {role}\\n\"\n",
    "            f\"Instruction: {instruction}\\n\"\n",
    "            f\"Output: {output}\"\n",
    "        )\n",
    "\n",
    "        image_part = Part.from_image(image_object)\n",
    "\n",
    "        contents = [prompt, image_part]\n",
    "        # Generate content using the local image\n",
    "        response = model.generate_content(contents)\n",
    "\n",
    "        pattern = r\"Item:\\s*(.*?)\\s*Description:\\s*(.*?)\\s*Material:\\s*(.*?)(?:\\n|$)\"\n",
    "\n",
    "        matches = re.findall(pattern, response.text, re.DOTALL)\n",
    "\n",
    "        items = []\n",
    "\n",
    "        for match in matches:\n",
    "            item, description, material = match\n",
    "            item_data = {\n",
    "                \"Item\": item.strip(),\n",
    "                \"Description\": description.strip(),\n",
    "                \"Material\": material.strip()\n",
    "            }\n",
    "            items.append(item_data)\n",
    "\n",
    "        items_list = \"\\n\".join([f\"Item: {item['Item']}, Description: {item['Description']}, Material: {item['Material']}\" for item in items])\n",
    "\n",
    "        model_2 = GenerativeModel(model_name=model_name_flash)\n",
    "\n",
    "        role_2 = \"You're an expert in environmental well-being, knowledgeable about recyclable, non-recyclable, reusable, and non-reusable items, their environmental impact, and innovative methods for recycling and reusing items.\"\n",
    "\n",
    "        instruction_2 = f\"\"\"Classify each identified item from {items_list} into any of these categories with explanation of why they belong to it based on each material: Recyclable, Non-Recyclable, Reusable, Non-Reusable.\n",
    "                           Ensure that no material is classified as both Recyclable and Non-Recyclable or both Reusable and Non-Reusable.\n",
    "                           If the identified item and materials are of organic matters then it should be classified as Non - Recyclable and Reusable.\n",
    "                           If same material is identified multiple times then do not give multiple times.\n",
    "                           Suggest two simple, DIY recycling methods for Recyclable items and two reusing methods for Reusable items by combining the identified items and materials.\n",
    "                           Ensure the output is in plain text without any markdown or formatting.\n",
    "        \"\"\"\n",
    "\n",
    "        output_2 = \"\"\"Material: [material]\n",
    "        Category: [category]\n",
    "        Explanation: [explanation]\n",
    "        Environmental impact: [impact]\n",
    "        Innovative methods: [methods]\"\"\"\n",
    "\n",
    "        prompt_2 = (\n",
    "            f\"role: {role_2}\\n\"\n",
    "            f\"Instruction: {instruction_2}\\n\"\n",
    "            f\"Output: {output_2}\"\n",
    "        )\n",
    "\n",
    "        # Send the final prompt 2 to the model\n",
    "        contents_2 = [prompt_2]\n",
    "        response_2 = model_2.generate_content(contents_2)\n",
    "\n",
    "        return response.text, response_2.text\n",
    "\n",
    "    async def upload_image(self, file: UploadFile) -> JSONResponse:\n",
    "        file_path = self.uploader.save_image(file)\n",
    "        response_text, classification_text = await self.classify_image(file_path)\n",
    "        combined_response = f\"{response_text}\\n\\n{classification_text}\"\n",
    "        return JSONResponse(content={\"message\": \"Image has been uploaded\", \"file_path\": file_path, \"classification\": combined_response})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
